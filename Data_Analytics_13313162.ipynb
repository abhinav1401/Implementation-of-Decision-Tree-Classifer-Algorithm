{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Analytics_13313162.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8OhUJPqJzkWb",
        "ALfOSJb9zr-w",
        "hqqo6d6s0gec"
      ],
      "authorship_tag": "ABX9TyNnFRW+r7ojARiaAQBqyVfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav1401/Implementation-of-Decision-Tree-Classifer-Algorithm/blob/main/Data_Analytics_13313162.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhUJPqJzkWb"
      },
      "source": [
        "#Import Required Python Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNM0Smg-zKYQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALfOSJb9zr-w"
      },
      "source": [
        "#Data Prepration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9IiccIz307"
      },
      "source": [
        "#Loading The Dataset\n",
        "\n",
        "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data',\n",
        "                names=['animal_name','hair','feathers','eggs','milk','airbone','aquatic','predator','toothed',\n",
        "                        'backbone','breathes','venomous','fins','legs','tail','domestic','catsize','Animal_Type',])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B326uW6g0k2U"
      },
      "source": [
        "#Drop The Unnecessary Columns\n",
        "\n",
        "df = df.drop('animal_name',axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN5VbBPk1IDP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "18c86938-b90e-4824-a246-4a185de05e77"
      },
      "source": [
        "#Printing The First 10 Rows of The Dataset\n",
        "\n",
        "print(df.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   hair  feathers  eggs  milk  ...  tail  domestic  catsize  Animal_Type\n",
            "0     1         0     0     1  ...     0         0        1            1\n",
            "1     1         0     0     1  ...     1         0        1            1\n",
            "2     0         0     1     0  ...     1         0        0            4\n",
            "3     1         0     0     1  ...     0         0        1            1\n",
            "4     1         0     0     1  ...     1         0        1            1\n",
            "5     1         0     0     1  ...     1         0        1            1\n",
            "6     1         0     0     1  ...     1         1        1            1\n",
            "7     0         0     1     0  ...     1         1        0            4\n",
            "8     0         0     1     0  ...     1         0        0            4\n",
            "9     1         0     0     1  ...     0         1        0            1\n",
            "\n",
            "[10 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J67hReNMUTvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9115d25a-b614-435d-d644-296e459903dd"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 101 entries, 0 to 100\n",
            "Data columns (total 17 columns):\n",
            " #   Column       Non-Null Count  Dtype\n",
            "---  ------       --------------  -----\n",
            " 0   hair         101 non-null    int64\n",
            " 1   feathers     101 non-null    int64\n",
            " 2   eggs         101 non-null    int64\n",
            " 3   milk         101 non-null    int64\n",
            " 4   airbone      101 non-null    int64\n",
            " 5   aquatic      101 non-null    int64\n",
            " 6   predator     101 non-null    int64\n",
            " 7   toothed      101 non-null    int64\n",
            " 8   backbone     101 non-null    int64\n",
            " 9   breathes     101 non-null    int64\n",
            " 10  venomous     101 non-null    int64\n",
            " 11  fins         101 non-null    int64\n",
            " 12  legs         101 non-null    int64\n",
            " 13  tail         101 non-null    int64\n",
            " 14  domestic     101 non-null    int64\n",
            " 15  catsize      101 non-null    int64\n",
            " 16  Animal_Type  101 non-null    int64\n",
            "dtypes: int64(17)\n",
            "memory usage: 13.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yov4C5p72FDl"
      },
      "source": [
        "#Data Splitting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZTaX8Iz2IbH"
      },
      "source": [
        "#Function to split the data into training and testing sets\n",
        "\n",
        "def train_test_split(df):\n",
        "    training_data = df.iloc[:90].reset_index(drop=True) #90% rows as training data\n",
        "    testing_data = df.iloc[30:].reset_index(drop=True) #30% rows as testing data\n",
        "    return training_data,testing_data\n",
        "\n",
        "training_data = train_test_split(df)[0]\n",
        "testing_data = train_test_split(df)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbIGewMJ1U-h"
      },
      "source": [
        "#Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW8QIs4I1XVb"
      },
      "source": [
        "#Function to Calculate the Entropy\n",
        "\n",
        "def calculate_entropy(target_column):\n",
        "    histogram = np.bincount(target_column)\n",
        "    ps = histogram / len(target_column)\n",
        "    result= -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AYQPQ3w1bNP"
      },
      "source": [
        "#Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFi3ZqBc1d_9"
      },
      "source": [
        "#Function to Calculate the Information Gain\n",
        "\n",
        "def Information_Gain(data,split_attribute_name,target_name=\"Animal_Type\"):\n",
        "\n",
        "    #Calculation of the Total Entropy\n",
        "    total_entropy = calculate_entropy(data[target_name])\n",
        "    \n",
        "    #Calculation of Split Counts and Values for the Attribure\n",
        "    values,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
        "\n",
        "    #Calculation of Weighted Entropy\n",
        "    weighted_entropyropy = np.sum([(counts[i]/np.sum(counts))*calculate_entropy(data.where(data[split_attribute_name]==values[i]).dropna()[target_name]) for i in range(len(values))])\n",
        "    \n",
        "    #Calculation of Information Gain\n",
        "    Information_Gain = total_entropy - weighted_entropyropy\n",
        "    \n",
        "    return Information_Gain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2BrUg1g1g6x"
      },
      "source": [
        "#Decision Tree Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63RTFCrH1ky6"
      },
      "source": [
        "#ID3 Decision Tree Algorithm\n",
        "\n",
        "def decision_tree_algorithm(data,original_data,features,target_attribute_name=\"Animal_Type\",parent_node_class = None):\n",
        "\n",
        "    # Statement to terminate the algorithm and return the leaf node\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]\n",
        "\n",
        "    #Returns the feature value from the original data if the training data is no row of data\n",
        "    elif len(data)==0:\n",
        "        return np.unique(original_data[target_attribute_name])[np.argmax(np.unique(original_data[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "    #Returns the parent node if the current node has no features\n",
        "    elif len(features) ==0:\n",
        "        return parent_node_class\n",
        "\n",
        "    #Tree Building Statements\n",
        "    else:\n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
        "\n",
        "        #Calculating the best split using information gain\n",
        "        item_values = [Information_Gain(data,feature,target_attribute_name) for feature in features]\n",
        "\n",
        "        #Calculating Information Gain and Features\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        #Tree Creation\n",
        "        tree = {best_feature:{}}\n",
        "\n",
        "        features = [i for i in features if i != best_feature]\n",
        "\n",
        "        #Recursive Tree\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            value = value\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            subtree = decision_tree_algorithm(sub_data,df,features,target_attribute_name,parent_node_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "        return(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXwi2gRJ1nol"
      },
      "source": [
        "#Prediction & Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Hi-QHa1rqU"
      },
      "source": [
        "#Function for Prediction\n",
        "\n",
        "def predict_data(query,tree,default = 1):\n",
        "\n",
        "    #Match each feature in query\n",
        "    for key in list(query.keys()):\n",
        "        if key in list(tree.keys()):\n",
        "\n",
        "            try:\n",
        "                result = tree[key][query[key]]\n",
        "            except:\n",
        "                return default\n",
        "\n",
        "            result = tree[key][query[key]]\n",
        "\n",
        "            if isinstance(result,dict):\n",
        "                return predict_data(query,result)\n",
        "\n",
        "            else:\n",
        "                return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJtxW37C2Bbz"
      },
      "source": [
        "#Function to test the data\n",
        "\n",
        "def test_data(data,tree):\n",
        "\n",
        "    #Converting the targeted column in dictionary format\n",
        "    queries = data.iloc[:,:-1].to_dict(orient = \"records\")\n",
        "\n",
        "    # To store the predicted data\n",
        "    predicted = pd.DataFrame(columns=[\"predicted\"])\n",
        "\n",
        "    #To calculate the accuracy of the prediction\n",
        "    for i in range(len(data)):\n",
        "        predicted.loc[i,\"predicted\"] = predict_data(queries[i],tree,1.0)\n",
        "    print('The Accuracy of Algorithm is : ',(np.sum(predicted[\"predicted\"] == data[\"Animal_Type\"])/len(data))*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIFhD2Vc2L8T"
      },
      "source": [
        "#Run Decision Tree Algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPPjDXPl2TBb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ab14998-90fe-44a6-ac7a-85577c5f1bca"
      },
      "source": [
        "tree = decision_tree_algorithm(training_data,training_data,training_data.columns[:-1])\n",
        "test_data(testing_data,tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy of Algorithm is :  97.1830985915493 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}